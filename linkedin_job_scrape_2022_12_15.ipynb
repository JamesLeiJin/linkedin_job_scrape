{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "SKwP6xqo6b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (4.7.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2022.6.15)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.12)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.0.4)\n",
      "Requirement already satisfied: outcome in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/leijin/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "# https://blog.devgenius.io/how-to-build-a-scraping-tool-for-linkedin-in-7-minutes-tool-data-science-csv-selenium-beautifulsoup-python-a673f12ac579\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QqvrsGn36KDD"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job name: Data Scientist\n"
     ]
    }
   ],
   "source": [
    "job_name = input(\"Enter the job name: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the job location: United States\n"
     ]
    }
   ],
   "source": [
    "country_name =input(\"Enter the job location: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "FqYsJGMi6ops",
    "outputId": "ab5777d2-c7fd-457f-a629-592c36ae2390"
   },
   "outputs": [],
   "source": [
    "# job_name = \"Data Scientist\"\n",
    "# country_name = \"United States\"\n",
    "\n",
    "job_url =\"\";\n",
    "for item in job_name.split(\" \"):\n",
    "    if item != job_name.split(\" \")[-1]:\n",
    "        job_url = job_url + item + \"%20\"\n",
    "    else:\n",
    "        job_url = job_url + item\n",
    "\n",
    "country_url =\"\";\n",
    "for item in country_name.split(\" \"):\n",
    "    if item != country_name.split(\" \")[-1]:\n",
    "        country_url = country_url + item + \"%20\"\n",
    "    else:\n",
    "        country_url = country_url + item\n",
    "\n",
    "url = \"https://www.linkedin.com/jobs/search?keywords={0}&location={1}&geoId=103644278&trk=public_jobs_jobs-search-bar_search-submit&position=1&pageNum=0\".format(job_url,country_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "G9weroyz-0LX",
    "outputId": "189a004a-12f9-4514-9906-4c2c850c947d"
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# from selenium import webdriver\n",
    "# def main():\n",
    "#     a = webdriver.Chrome()\n",
    "#     a.get('https://www.google.com')\n",
    "#     time.sleep(5)\n",
    "#     a.quit()\n",
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "T3crarDT68ib",
    "outputId": "cc131011-6dde-4050-eefe-a387914beaa2"
   },
   "outputs": [],
   "source": [
    "# Creating a webdriver instance\n",
    "driver = webdriver.Chrome(\"ChromeDriver_Path/chromedriver\")\n",
    "# Opening the url we have just defined in our browser\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31000\n"
     ]
    }
   ],
   "source": [
    "#We find how many jobs are offered.\n",
    "jobs_num = driver.find_element(By.CSS_SELECTOR,\"h1>span\").get_attribute(\"innerText\")\n",
    "if len(jobs_num.split(',')) > 1:\n",
    "    jobs_num = int(jobs_num.split(',')[0])*100\n",
    "else:\n",
    "    jobs_num = int(jobs_num)\n",
    "\n",
    "jobs_num   = int(jobs_num)\n",
    "print(jobs_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the numbers of jobs needed: 100\n"
     ]
    }
   ],
   "source": [
    "numbers = input(\"Enter the numbers of jobs needed: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current at:  52 Percentage at:  103.921568627451 % %\r"
     ]
    }
   ],
   "source": [
    "#We create a while loop to browse all jobs. \n",
    "numbers = int(numbers)\n",
    "i = 2\n",
    "while i <= int(numbers/2)+1:\n",
    "    #We keep scrollind down to the end of the view.\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    i = i + 1\n",
    "    print(\"Current at: \", i, \"Percentage at: \", ((i+1)/(int(numbers/2)+1))*100, \"%\",end=\"\\r\")\n",
    "    try:\n",
    "        #We try to click on the load more results buttons in case it is already displayed.\n",
    "        infinite_scroller_button = driver.find_element(By.XPATH, \".//button[@aria-label='Load more results']\")\n",
    "        infinite_scroller_button.click()\n",
    "        time.sleep(0.1)\n",
    "    except:\n",
    "        #If there is no button, there will be an error, so we keep scrolling down.\n",
    "        time.sleep(0.1)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist (Deep Learning), Peacock</td>\n",
       "      <td>Peacock</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amicus</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jr. Data Scientist</td>\n",
       "      <td>UMortgage</td>\n",
       "      <td>Greater Philadelphia</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/jr-data-sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist Full Time</td>\n",
       "      <td>Bardess Group Ltd</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BICP</td>\n",
       "      <td>Beaverton, OR</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Marketing Analytics</td>\n",
       "      <td>Spotify</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist I</td>\n",
       "      <td>Three Point Solutions, Inc.</td>\n",
       "      <td>Waterloo, IA</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Dezign Concepts</td>\n",
       "      <td>McLean, VA</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist, Jr.</td>\n",
       "      <td>Altamira Technologies Corporation</td>\n",
       "      <td>Fort Bragg, NC</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>ClearML</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>Etsy</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>FocusKPI, Inc.</td>\n",
       "      <td>San Francisco, CA</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist, Jr.</td>\n",
       "      <td>Altamira Technologies Corporation</td>\n",
       "      <td>Camp Lejeune, NC</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>duvari</td>\n",
       "      <td>Chesterfield, MO</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Shtudy</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>2022-12-08</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/machine-lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist (REMOTE)</td>\n",
       "      <td>Foot Locker</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-16</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atrium</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-06</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>The Fresh Market</td>\n",
       "      <td>Greensboro--Winston-Salem--High Point Area</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Dezign Concepts</td>\n",
       "      <td>Virginia, United States</td>\n",
       "      <td>2022-12-07</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Envision</td>\n",
       "      <td>Greater St. Louis</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Grey Matters Defense Solutions, LLC</td>\n",
       "      <td>Aurora, CO</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientists (Multiple Positions)</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>eimagine</td>\n",
       "      <td>United States</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Scientist, Jr.</td>\n",
       "      <td>Altamira Technologies Corporation</td>\n",
       "      <td>Hurlburt Field, FL</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Smith Hanley Associates</td>\n",
       "      <td>Needham, MA</td>\n",
       "      <td>2022-12-12</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-scient...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Job Title  \\\n",
       "0   Data Scientist (Deep Learning), Peacock   \n",
       "1                            Data Scientist   \n",
       "2                        Jr. Data Scientist   \n",
       "3                  Data Scientist Full Time   \n",
       "4                            Data Scientist   \n",
       "5      Data Scientist - Marketing Analytics   \n",
       "6                          Data Scientist I   \n",
       "7                     Junior Data Scientist   \n",
       "8                       Data Scientist, Jr.   \n",
       "9                     Junior Data Scientist   \n",
       "10        Data Scientist, Product Analytics   \n",
       "11                           Data Scientist   \n",
       "12                      Data Scientist, Jr.   \n",
       "13          Data Scientist Machine Learning   \n",
       "14                Machine Learning Engineer   \n",
       "15                  Data Scientist (REMOTE)   \n",
       "16                           Data Scientist   \n",
       "17                           Data Scientist   \n",
       "18                           Data Scientist   \n",
       "19                           Data Scientist   \n",
       "20                           Data Scientist   \n",
       "21     Data Scientists (Multiple Positions)   \n",
       "22                           Data Scientist   \n",
       "23                      Data Scientist, Jr.   \n",
       "24                           Data Scientist   \n",
       "\n",
       "                                Company  \\\n",
       "0                               Peacock   \n",
       "1                                Amicus   \n",
       "2                             UMortgage   \n",
       "3                     Bardess Group Ltd   \n",
       "4                                  BICP   \n",
       "5                               Spotify   \n",
       "6           Three Point Solutions, Inc.   \n",
       "7                       Dezign Concepts   \n",
       "8     Altamira Technologies Corporation   \n",
       "9                               ClearML   \n",
       "10                                 Etsy   \n",
       "11                       FocusKPI, Inc.   \n",
       "12    Altamira Technologies Corporation   \n",
       "13                               duvari   \n",
       "14                               Shtudy   \n",
       "15                          Foot Locker   \n",
       "16                               Atrium   \n",
       "17                     The Fresh Market   \n",
       "18                      Dezign Concepts   \n",
       "19                             Envision   \n",
       "20  Grey Matters Defense Solutions, LLC   \n",
       "21                               PayPal   \n",
       "22                             eimagine   \n",
       "23    Altamira Technologies Corporation   \n",
       "24              Smith Hanley Associates   \n",
       "\n",
       "                                      Location        Date  \\\n",
       "0                                 New York, NY  2022-12-06   \n",
       "1                                 New York, NY  2022-12-06   \n",
       "2                         Greater Philadelphia  2022-12-09   \n",
       "3                                 New York, NY  2022-12-06   \n",
       "4                                Beaverton, OR  2022-12-05   \n",
       "5                                 New York, NY  2022-12-08   \n",
       "6                                 Waterloo, IA  2022-12-12   \n",
       "7                                   McLean, VA  2022-12-12   \n",
       "8                               Fort Bragg, NC  2022-12-14   \n",
       "9                                United States  2022-12-16   \n",
       "10                                Brooklyn, NY  2022-12-14   \n",
       "11                           San Francisco, CA  2022-12-14   \n",
       "12                            Camp Lejeune, NC  2022-12-12   \n",
       "13                            Chesterfield, MO  2022-12-08   \n",
       "14                              Washington, DC  2022-12-08   \n",
       "15                               United States  2022-12-16   \n",
       "16                               United States  2022-12-06   \n",
       "17  Greensboro--Winston-Salem--High Point Area  2022-12-07   \n",
       "18                     Virginia, United States  2022-12-07   \n",
       "19                           Greater St. Louis  2022-12-09   \n",
       "20                                  Aurora, CO  2022-12-09   \n",
       "21                                San Jose, CA  2022-12-09   \n",
       "22                               United States  2022-12-14   \n",
       "23                          Hurlburt Field, FL  2022-12-14   \n",
       "24                                 Needham, MA  2022-12-12   \n",
       "\n",
       "                                                 Link  \n",
       "0   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "1   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "2   https://www.linkedin.com/jobs/view/jr-data-sci...  \n",
       "3   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "4   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "5   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "6   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "7   https://www.linkedin.com/jobs/view/junior-data...  \n",
       "8   https://www.linkedin.com/jobs/view/data-scient...  \n",
       "9   https://www.linkedin.com/jobs/view/junior-data...  \n",
       "10  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "11  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "12  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "13  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "14  https://www.linkedin.com/jobs/view/machine-lea...  \n",
       "15  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "16  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "17  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "18  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "19  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "20  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "21  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "22  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "23  https://www.linkedin.com/jobs/view/data-scient...  \n",
       "24  https://www.linkedin.com/jobs/view/data-scient...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We get a list containing all jobs that we have found.\n",
    "job_lists = driver.find_element(By.CLASS_NAME,\"jobs-search__results-list\")\n",
    "jobs = job_lists.find_elements(By.TAG_NAME,\"li\") # return a list\n",
    "\n",
    "#We declare void list to keep track of all obtaind data.\n",
    "job_title_list = []\n",
    "company_name_list = []\n",
    "location_list = []\n",
    "date_list = []\n",
    "job_link_list = []\n",
    "\n",
    "#We loof over every job and obtain all the wanted info.\n",
    "for job in jobs:\n",
    "    #job_title\n",
    "    job_title = job.find_element(By.CSS_SELECTOR,\"h3\").get_attribute(\"innerText\")\n",
    "    job_title_list.append(job_title)\n",
    "    \n",
    "    #company_name\n",
    "    company_name = job.find_element(By.CSS_SELECTOR,\"h4\").get_attribute(\"innerText\")\n",
    "    company_name_list.append(company_name)\n",
    "    \n",
    "    #location\n",
    "    location = job.find_element(By.CSS_SELECTOR,\"div>div>span\").get_attribute(\"innerText\")\n",
    "    location_list.append(location)\n",
    "    \n",
    "    #date\n",
    "    date = job.find_element(By.CSS_SELECTOR,\"div>div>time\").get_attribute(\"datetime\")\n",
    "    date_list.append(date)\n",
    "    \n",
    "    #job_link\n",
    "    job_link = job.find_element(By.CSS_SELECTOR,\"a\").get_attribute(\"href\")\n",
    "    job_link_list.append(job_link)\n",
    "\n",
    "jobs_df = pd.DataFrame({'Job Title': job_title_list,\n",
    "              'Company': company_name_list,\n",
    "              'Location': location_list,\n",
    "              'Date': date_list,\n",
    "              'Link': job_link_list\n",
    "            })\n",
    "jobs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "jobs_df.to_csv('Sample_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
